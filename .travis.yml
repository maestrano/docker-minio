---
sudo: required
dist: trusty

services:
  - docker

before_install:
  - sudo apt-get install -y curl

script:
  # Install AWS CLI (ubuntu-provided one is generally old)
  - curl "https://bootstrap.pypa.io/get-pip.py" -o "get-pip.py"
  - python get-pip.py --user
  - pip install awscli --user

  # Build docker image
  - cd 2.0/
  - docker build -t maestrano/minio:travis . > /dev/null 2>&1

  # Set access keys (region is only set to make the CLI happy)
  - export AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
  - export AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
  - export AWS_DEFAULT_REGION=us-west-1
  - export DEFAULT_BUCKET=app-bucket

  #=======================================
  # Test with minimal parameters
  #=======================================
  # Run image
  - docker run -p 9000:9000 -d --name travis-test -e "MINIO_ACCESS_KEY=$AWS_ACCESS_KEY_ID" -e "MINIO_SECRET_KEY=$AWS_SECRET_ACCESS_KEY" -e "MINIO_BUCKET=$DEFAULT_BUCKET" maestrano/minio:travis

  # Get ip address
  - "container_ip=`docker inspect --format '{{ .NetworkSettings.IPAddress }}' travis-test`"

  # Wait for container to be ready
  - try_count=0;
  - HEALTH_CHECK="starting"
  - while [ "$HEALTH_CHECK" == "starting" ] || [ "$HEALTH_CHECK" == "unhealthy" ]; do let "try_count++"; [ $try_count -gt 100 ] && exit 20; sleep 5; HEALTH_CHECK=$(docker inspect --format='{{.State.Health.Status}}' travis-test 2>/dev/null); done

  # Set storage endpoint
  - export S3_ENDPOINT="http://${container_ip}:9000"

  # Check that application is up
  - "curl -H 'User-Agent: Mozilla' -f $S3_ENDPOINT/minio/login"

  # Create bucket
  - "aws --endpoint-url $S3_ENDPOINT s3 mb s3://mybucket"

  # Add object to bucket
  - touch myfile.txt
  - "aws --endpoint-url $S3_ENDPOINT s3 cp myfile.txt s3://mybucket"
  - "aws --endpoint-url $S3_ENDPOINT s3 cp myfile.txt s3://$DEFAULT_BUCKET"

  # Download file from created bucket
  - rm -f myfile.txt
  - "aws --endpoint-url $S3_ENDPOINT s3 cp s3://mybucket/myfile.txt myfile.txt"
  - '[ -f myfile.txt ]'

  # Download file from default bucket
  - rm -f myfile.txt
  - "aws --endpoint-url $S3_ENDPOINT s3 cp s3://$DEFAULT_BUCKET/myfile.txt myfile.txt"
  - '[ -f myfile.txt ]'

  # Perform successive backups
  - for i in {30..0}; do docker exec -it travis-test /usr/local/bin/backup.sh; sleep 1; done

  # Check that only 20 backups are kept
  - "bkup_count=$(docker exec -it travis-test ls -l /snapshots | grep tar.gz | wc -l)"
  - '[ "$bkup_count" == "20" ]'

  # Perform recovery
  - docker exec -it travis-test rm -rf /export/*
  - docker exec -it travis-test sh -c "tar -xvzf /snapshots/\$(ls -1r /snapshots/ | head -n 1) -C /"

  # Check integrity: download file from created bucket
  - rm -f myfile.txt
  - "aws --endpoint-url $S3_ENDPOINT s3 cp s3://mybucket/myfile.txt myfile.txt"
  - '[ -f myfile.txt ]'

  # Check integrity: download file from default bucket
  - rm -f myfile.txt
  - "aws --endpoint-url $S3_ENDPOINT s3 cp s3://$DEFAULT_BUCKET/myfile.txt myfile.txt"
  - '[ -f myfile.txt ]'

  # Remove container
  - docker rm -f travis-test
